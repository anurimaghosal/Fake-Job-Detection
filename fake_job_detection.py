# -*- coding: utf-8 -*-
"""Fake_job_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QlJSG4IJAJ__uRTbjIMDtv_h6_rYDUIb
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
df=pd.read_csv('/content/fake_job_postings.csv.zip')

df.head(5)

df.shape

df['description']

df.isnull().sum()

df1=df.drop(['job_id','department','salary_range','telecommuting','has_company_logo','has_questions','employment_type','required_education'],axis=1)
df1.shape

df1.isnull().sum()

df1.drop(['required_experience'],axis=1,inplace=True)
df1.shape

df1.dropna(inplace=True)
df1.shape

df1.shape

df1.head(20)

import string
df1['description'] = df1['description'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).split())

df1

df1['company_profile'] = df1['company_profile'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).split())
df1['requirements'] = df1['requirements'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).split())
df1['benefits'] = df1['benefits'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).split())
df1['industry'] = df1['industry'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).split())

df1['function']=df1['function'].apply(lambda x:x.translate(str.maketrans('','',string.punctuation)).split())
df1['title']=df1['title'].apply(lambda x:x.translate(str.maketrans('','',string.punctuation)).split())

df1.drop(['location'],axis=1,inplace=True)

df1

df1['tag']=df1['title']+df1['company_profile']+df1['description']+df1['requirements']+df1['benefits']+df1['industry']+df1['function']

df1

new_df=df1[['tag','fraudulent']]
new_df

new_df.tag[3]



new_df['tag'].apply(lambda x:" ".join(x))

new_df['tag'][1]

new_df['tag'] = new_df['tag'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)

new_df['tag'][1]

import re
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text

new_df['tag'] = new_df['tag'].apply(preprocess_text)

# Display the cleaned text
print(new_df['tag'].iloc[0])

import nltk
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():
    y.append(ps.stem(i))
  return " ".join (y)

new_df['tag']=new_df['tag'].apply(stem)

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000,stop_words='english')
X=cv.fit_transform(new_df['tag']).toarray()

print(X.shape)

cv.get_feature_names_out()

new_df['tag'][1]

new_df



y=new_df['fraudulent']

print(len(y))

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))

# Map back a few examples to see how the model performs
for i in range(5):
    print(f"\nText: {' '.join(new_df['tag'].iloc[i].split()[:50])}...")  # print first 50 words
    print(f"Actual: {'Fraudulent' if y_test.iloc[i] == 1 else 'Real'}")
    print(f"Predicted: {'Fraudulent' if y_pred[i] == 1 else 'Real'}")

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Real", "Fraudulent"], yticklabels=["Real", "Fraudulent"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

def predict_fake_job(text, vectorizer, model):
    # Preprocessing
    text = preprocess_text(text)
    text = stem(text)
    text_vectorized = vectorizer.transform([text])
    prediction = model.predict(text_vectorized)[0]
    print("Prediction:", "Fraudulent" if prediction == 1 else "Real")

sample_job = "Data entry clerk needed, no experience required, earn $5000 a week. Apply now!"
predict_fake_job(sample_job, cv, model)